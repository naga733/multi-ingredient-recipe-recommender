{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO Multi-Ingredient Detection — Cleaned Version\n",
        "\n",
        "This notebook is a **cleaned-up version** of my YOLO training workflow.  \n",
        "\n",
        "I ran several experiments with different datasets, methods, and hyperparameter settings while developing the project. To keep things clear and easy to follow, I’ve removed all the trial runs, intermediate results, and extra code.\n",
        "\n",
        "\n",
        "This notebook contains only the **essential code** needed to reproduce the YOLO training for multi-ingredient detection in the\n",
        "project.\n",
        "\n"
      ],
      "metadata": {
        "id": "8W2RaAvLJ0al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install fiftyone\n",
        "!pip install torch torchvision\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "m5ZjeSNOxRQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "import os\n",
        "import random\n",
        "import yaml\n",
        "from shutil import copy2\n",
        "\n",
        "classes = [\"Apple\",\"Banana\", \"Grape\",\"Milk\",\"Bell pepper\", \"Bread\", \"Broccoli\", \"Cucumber\", \"Egg (Food)\", \"Zucchini\", \"Lemon\", \"Orange\", \"Tomato\", \"Cabbage\", \"Carrot\"]\n",
        "sample_limit_per_class = 500\n",
        "\n",
        "# Load Open Images v7 dataset with specified classes and sample limit\n",
        "view = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    split=\"train\",\n",
        "    label_types=[\"detections\"],\n",
        "    classes=classes,\n",
        "    max_samples=sample_limit_per_class * len(classes),\n",
        ")\n",
        "\n",
        "# schema to verify label fields\n",
        "print(view.schema)\n",
        "\n",
        "label_field = \"ground_truth\"\n",
        "\n",
        "# export directories\n",
        "export_dir = \"/content/open_images_data\"\n",
        "train_dir = os.path.join(export_dir, 'train')\n",
        "val_dir = os.path.join(export_dir, 'val')\n",
        "test_dir = os.path.join(export_dir, 'test')\n",
        "\n",
        "# Directories for train, validation, and test splits\n",
        "for subset in [train_dir, val_dir, test_dir]:\n",
        "    os.makedirs(os.path.join(subset, 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(subset, 'labels'), exist_ok=True)\n",
        "\n",
        "# Shuffle and split dataset into train (80%), validation (10%), and test (10%)\n",
        "samples = list(view)\n",
        "random.shuffle(samples)\n",
        "train_samples = samples[:int(0.8 * len(samples))]\n",
        "val_samples = samples[int(0.8 * len(samples)):int(0.9 * len(samples))]\n",
        "test_samples = samples[int(0.9 * len(samples)):]\n",
        "\n",
        "# Function to copy images and generate YOLO-format label files\n",
        "def copy_files(samples, subset_dir):\n",
        "    for sample in samples:\n",
        "        # Copy image file to target directory\n",
        "        image_file = sample.filepath\n",
        "        image_filename = os.path.basename(image_file)\n",
        "        copy2(image_file, os.path.join(subset_dir, 'images', image_filename))\n",
        "\n",
        "        # Ensure sample contains valid detections\n",
        "        if label_field in sample and sample[label_field] is not None and len(sample[label_field].detections) > 0:\n",
        "            label_filename = os.path.splitext(image_filename)[0] + '.txt'\n",
        "            label_path = os.path.join(subset_dir, 'labels', label_filename)\n",
        "\n",
        "            with open(label_path, 'w') as label_file:\n",
        "                for detection in sample[label_field].detections:\n",
        "                    # Only include detections for target classes\n",
        "                    if detection.label in classes:\n",
        "                        class_id = classes.index(detection.label)\n",
        "                        bbox = detection.bounding_box\n",
        "                        x_center = max(0, min(1, bbox[0] + bbox[2] / 2))\n",
        "                        y_center = max(0, min(1, bbox[1] / 2))\n",
        "                        width = max(0, min(1, bbox[2]))\n",
        "                        height = max(0, min(1, bbox[3]))\n",
        "\n",
        "                        # Write normalized bounding box coordinates\n",
        "                        label_file.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "        else:\n",
        "            print(f\"Warning: No labels found for image: {image_filename}\")\n",
        "\n",
        "copy_files(train_samples, train_dir)\n",
        "copy_files(val_samples, val_dir)\n",
        "copy_files(test_samples, test_dir)\n",
        "\n",
        "# Generate YOLO data configuration (data.yaml)\n",
        "data_yaml = {\n",
        "    'train': os.path.join(export_dir, 'train/images'),\n",
        "    'val': os.path.join(export_dir, 'val/images'),\n",
        "    'test': os.path.join(export_dir, 'test/images'),\n",
        "    'nc': len(classes),  # Number of classes\n",
        "    'names': classes,    # Class names\n",
        "}\n",
        "\n",
        "# Save data.yaml to export directory\n",
        "yaml_path = os.path.join(export_dir, 'data.yaml')\n",
        "with open(yaml_path, 'w') as yaml_file:\n",
        "    yaml.dump(data_yaml, yaml_file)\n",
        "\n",
        "print(f\"Dataset exported to: {export_dir}\")\n",
        "print(f\"data.yaml file created at: {yaml_path}\")\n"
      ],
      "metadata": {
        "id": "i9UOo0krJop-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install augmentation libraries\n",
        "!pip install --quiet albumentations==1.3.0 opencv-python-headless==4.7.0.72"
      ],
      "metadata": {
        "id": "e5BvTj25yWMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script rebuilds YOLO label files from a FiftyOne dataset. For each image, it copies the file into a new folder and creates a matching .txt label file that YOLO expects. It converts the bounding boxes from FiftyOne’s format - which uses the top-left corner - into YOLO’s format, which uses the box center and normalized values between 0 and 1. It also makes sure the coordinates stay valid and skips any labels that don’t match your class list."
      ],
      "metadata": {
        "id": "oycJdIss0act"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Basically cleanup step to make sure correct formatting\n",
        "import os\n",
        "from shutil import copy2\n",
        "\n",
        "def regenerate_labels_from_fiftyone(samples_list, dest_dir, label_field, classes_list):\n",
        "    images_dir = os.path.join(dest_dir, \"images\")\n",
        "    labels_dir = os.path.join(dest_dir, \"labels\")\n",
        "    os.makedirs(images_dir, exist_ok=True)\n",
        "    os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "    written = 0\n",
        "    for sample in samples_list:\n",
        "        src_img = sample.filepath\n",
        "        img_name = os.path.basename(src_img)\n",
        "        dst_img = os.path.join(images_dir, img_name)\n",
        "\n",
        "        # Copying image if not present\n",
        "        if not os.path.exists(dst_img):\n",
        "            try:\n",
        "                copy2(src_img, dst_img)\n",
        "            except Exception as e:\n",
        "                print(f\"Could not copy {src_img}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # compose the label path\n",
        "        label_path = os.path.join(labels_dir, os.path.splitext(img_name)[0] + \".txt\")\n",
        "        # Removing any existing label file to avoid duplicates\n",
        "        if os.path.exists(label_path):\n",
        "            os.remove(label_path)\n",
        "\n",
        "        # Writing labels if detections exist\n",
        "        if label_field in sample and sample[label_field] is not None and len(sample[label_field].detections) > 0:\n",
        "            with open(label_path, \"w\") as lf:\n",
        "                for det in sample[label_field].detections:\n",
        "                    if det.label not in classes_list:\n",
        "                        continue\n",
        "                    cls_id = classes_list.index(det.label)\n",
        "                    x_min, y_min, w, h = det.bounding_box\n",
        "                    x_center = x_min + w / 2.0\n",
        "                    y_center = y_min + h / 2.0\n",
        "                    x_center = max(0.0, min(1.0, x_center))\n",
        "                    y_center = max(0.0, min(1.0, y_center))\n",
        "                    w = max(0.0, min(1.0, w))\n",
        "                    h = max(0.0, min(1.0, h))\n",
        "                    lf.write(f\"{cls_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "                    written += 1\n",
        "    print(f\"Regenerated {written} bounding boxes in {dest_dir}\")\n",
        "\n",
        "regenerate_labels_from_fiftyone(train_samples, train_dir, label_field, classes)\n",
        "regenerate_labels_from_fiftyone(val_samples, val_dir, label_field, classes)\n",
        "regenerate_labels_from_fiftyone(test_samples, test_dir, label_field, classes)\n"
      ],
      "metadata": {
        "id": "tqKevqsPy0IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of bounding boxes per class (train/val/test)\n",
        "import glob\n",
        "from collections import Counter\n",
        "\n",
        "def count_bboxes_in_labels(labels_folder):\n",
        "    counts = Counter()\n",
        "    for txt_path in glob.glob(os.path.join(labels_folder, \"*.txt\")):\n",
        "        with open(txt_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                parts = line.split()\n",
        "                try:\n",
        "                    cid = int(parts[0])\n",
        "                    counts[cid] += 1\n",
        "                except:\n",
        "                    pass\n",
        "    return counts\n",
        "\n",
        "train_counts = count_bboxes_in_labels(os.path.join(train_dir, \"labels\"))\n",
        "val_counts = count_bboxes_in_labels(os.path.join(val_dir, \"labels\"))\n",
        "test_counts = count_bboxes_in_labels(os.path.join(test_dir, \"labels\"))\n",
        "\n",
        "print(\"Index -> Class name\")\n",
        "for i, name in enumerate(classes):\n",
        "    print(f\"{i:02d} -> {name}\")\n",
        "\n",
        "print(\"\\nTrain counts (per-class):\")\n",
        "for i, name in enumerate(classes):\n",
        "    print(f\"{i:02d} {name:15s}: {train_counts.get(i,0)}\")\n",
        "\n",
        "print(\"\\nValidation counts (per-class):\")\n",
        "for i, name in enumerate(classes):\n",
        "    print(f\"{i:02d} {name:15s}: {val_counts.get(i,0)}\")\n",
        "\n",
        "print(\"\\nTest counts (per-class):\")\n",
        "for i, name in enumerate(classes):\n",
        "    print(f\"{i:02d} {name:15s}: {test_counts.get(i,0)}\")\n",
        "\n",
        "most_common = train_counts.most_common(3)\n",
        "least_common = sorted([(k, train_counts.get(k,0)) for k in range(len(classes))], key=lambda x: x[1])[:3]\n",
        "print(\"\\nTop 3 classes (train):\", [(classes[k], v) for k,v in most_common])\n",
        "print(\"Bottom 3 classes (train):\", [(classes[k], v) for k,v in least_common])\n"
      ],
      "metadata": {
        "id": "Bmhp0W9N00k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Targeted augmentation for underrepresented classes.\n",
        "\n",
        "This code finds underrepresented classes in your training set and automatically creates more images for them by flipping, rotating, and tweaking brightness and color. It keeps all the YOLO labels accurate and normalized, so your dataset becomes more balanced and your model learns better."
      ],
      "metadata": {
        "id": "rYSXNqYw1FjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import uuid\n",
        "import random\n",
        "from pathlib import Path\n",
        "import albumentations as A\n",
        "\n",
        "images_dir = Path(train_dir) / \"images\"\n",
        "labels_dir = Path(train_dir) / \"labels\"\n",
        "\n",
        "largest_class_count = max(train_counts.values()) if train_counts else 0\n",
        "TARGET_PER_CLASS = max(largest_class_count, 500)  # aim to bring every class up to this many boxes\n",
        "AUG_PER_IMAGE = 2  # number of augmented variants per selected image\n",
        "OUT_IMG_EXT = \".jpg\"\n",
        "\n",
        "aug = A.Compose(\n",
        "    [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.RandomRotate90(p=0.3),\n",
        "        A.ShiftScaleRotate(shift_limit=0.06, scale_limit=0.15, rotate_limit=18, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
        "        A.RandomBrightnessContrast(p=0.5),\n",
        "        A.HueSaturationValue(p=0.35),\n",
        "        A.GaussNoise(p=0.15),\n",
        "        A.Resize(640, 640, p=1.0),\n",
        "    ],\n",
        "    bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"labels\"])\n",
        ")\n",
        "\n",
        "def yolo_to_pascal(bbox, img_w, img_h):\n",
        "    cx, cy, w, h = bbox\n",
        "    x_min = (cx - w/2.0) * img_w\n",
        "    y_min = (cy - h/2.0) * img_h\n",
        "    x_max = (cx + w/2.0) * img_w\n",
        "    y_max = (cy + h/2.0) * img_h\n",
        "    return [x_min, y_min, x_max, y_max]\n",
        "\n",
        "def pascal_to_yolo(box, img_w, img_h):\n",
        "    x_min, y_min, x_max, y_max = box\n",
        "    w = (x_max - x_min) / img_w\n",
        "    h = (y_max - y_min) / img_h\n",
        "    cx = (x_min + x_max) / 2.0 / img_w\n",
        "    cy = (y_min + y_max) / 2.0 / img_h\n",
        "    return [cx, cy, w, h]\n",
        "\n",
        "# Building a map: basename -> list of (class_id, bbox_yolo)\n",
        "image_to_boxes = {}\n",
        "for label_file in labels_dir.glob(\"*.txt\"):\n",
        "    base = label_file.stem\n",
        "    with open(label_file, \"r\") as f:\n",
        "        lines = [l.strip() for l in f if l.strip()]\n",
        "    boxes = []\n",
        "    for line in lines:\n",
        "        parts = line.split()\n",
        "        cid = int(parts[0])\n",
        "        cx, cy, w, h = map(float, parts[1:5])\n",
        "        boxes.append((cid, (cx, cy, w, h)))\n",
        "    if boxes:\n",
        "        image_to_boxes[base] = boxes\n",
        "\n",
        "# Reverse mapping class -> list of basenames\n",
        "class_to_images = {i: [] for i in range(len(classes))}\n",
        "for base, boxes in image_to_boxes.items():\n",
        "    for cid, _ in boxes:\n",
        "        class_to_images[cid].append(base)\n",
        "\n",
        "# Performing augmentation for classes that are below target\n",
        "augmented_images = 0\n",
        "for cid in range(len(classes)):\n",
        "    current = train_counts.get(cid, 0)\n",
        "    if current >= TARGET_PER_CLASS:\n",
        "        continue\n",
        "    needed = TARGET_PER_CLASS - current\n",
        "    candidates = class_to_images.get(cid, []).copy()\n",
        "    if not candidates:\n",
        "        print(f\"Skipping class {cid} ({classes[cid]}): no training images to augment.\")\n",
        "        continue\n",
        "    print(f\"Augmenting class {cid} ({classes[cid]}): current {current}, target {TARGET_PER_CLASS}, needed {needed}\")\n",
        "    # randomly picking candidates\n",
        "    while needed > 0 and candidates:\n",
        "        base = random.choice(candidates)\n",
        "        matches = list(images_dir.glob(base + \".*\"))\n",
        "        if not matches:\n",
        "            candidates.remove(base)\n",
        "            continue\n",
        "        img_path = str(matches[0])\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            candidates.remove(base)\n",
        "            continue\n",
        "        h, w = img.shape[:2]\n",
        "        orig_boxes = []\n",
        "        labels_for_aug = []\n",
        "        lbl_path = labels_dir / (base + \".txt\")\n",
        "        with open(lbl_path, \"r\") as lf:\n",
        "            for line in lf:\n",
        "                parts = line.split()\n",
        "                lab = int(parts[0])\n",
        "                cx, cy, bw, bh = map(float, parts[1:5])\n",
        "                pascal = yolo_to_pascal((cx, cy, bw, bh), w, h)\n",
        "                if (pascal[2] - pascal[0] < 3) or (pascal[3] - pascal[1] < 3):\n",
        "                    continue\n",
        "                orig_boxes.append(pascal)\n",
        "                labels_for_aug.append(lab)\n",
        "        if not orig_boxes:\n",
        "            candidates.remove(base)\n",
        "            continue\n",
        "\n",
        "        # create a few augmented variants from this image\n",
        "        for _ in range(min(AUG_PER_IMAGE, needed)):\n",
        "            try:\n",
        "                res = aug(image=img, bboxes=orig_boxes, labels=labels_for_aug)\n",
        "            except Exception as e:\n",
        "                # if augmentation fails\n",
        "                break\n",
        "            out_img = res[\"image\"]\n",
        "            out_bboxes = res[\"bboxes\"]\n",
        "            out_labels = res[\"labels\"]\n",
        "            # saving results\n",
        "            new_base = f\"{base}_aug_{uuid.uuid4().hex[:8]}\"\n",
        "            out_img_path = images_dir / (new_base + OUT_IMG_EXT)\n",
        "            cv2.imwrite(str(out_img_path), out_img)\n",
        "\n",
        "            ih, iw = out_img.shape[:2]\n",
        "            out_label_path = labels_dir / (new_base + \".txt\")\n",
        "            with open(out_label_path, \"w\") as olf:\n",
        "                for lab, box in zip(out_labels, out_bboxes):\n",
        "                    yolo_box = pascal_to_yolo(box, iw, ih)\n",
        "                    cx, cy, bw, bh = [max(0.0, min(1.0, v)) for v in yolo_box]\n",
        "                    olf.write(f\"{lab} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
        "            augmented_images += 1\n",
        "            needed -= 1\n",
        "            if needed <= 0:\n",
        "                break\n",
        "\n",
        "print(f\"Augmentation finished. Added {augmented_images} new augmented images.\")\n"
      ],
      "metadata": {
        "id": "VWDazgve1C4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code randomly picks four training images, stitches them together into a single mosaic, and updates all the bounding boxes so they line up correctly. It’s a clean way to make your dataset more diverse and help your YOLO model generalize better.\n",
        "\n",
        "This cell synthesizes new images by placing four training images into a single image (mosaic). It adjusts and writes bounding boxes accordingly."
      ],
      "metadata": {
        "id": "r6tXZg202wnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_mosaic_image(basenames, images_dir, labels_dir, out_image_path, out_label_path, target_size=640):\n",
        "    # Canvas\n",
        "    canvas = np.full((target_size, target_size, 3), 114, dtype=np.uint8)\n",
        "    half = target_size // 2\n",
        "    offsets = [(0,0), (half,0), (0,half), (half,half)]\n",
        "    accumulated_boxes = []\n",
        "    accumulated_labels = []\n",
        "\n",
        "    for i, base in enumerate(basenames[:4]):\n",
        "        img_matches = list(images_dir.glob(base + \".*\"))\n",
        "        lbl_path = labels_dir / (base + \".txt\")\n",
        "        if not img_matches or not lbl_path.exists():\n",
        "            continue\n",
        "        img = cv2.imread(str(img_matches[0]))\n",
        "        if img is None:\n",
        "            continue\n",
        "        h0, w0 = img.shape[:2]\n",
        "        # Resizing to half x half ignoring aspect ratio for simplicity\n",
        "        img_resized = cv2.resize(img, (half, half))\n",
        "        x_off, y_off = offsets[i]\n",
        "        canvas[y_off:y_off+half, x_off:x_off+half] = img_resized\n",
        "\n",
        "        # transforming original boxes to new position\n",
        "        with open(lbl_path, \"r\") as lf:\n",
        "            for line in lf:\n",
        "                parts = line.split()\n",
        "                lab = int(parts[0])\n",
        "                cx, cy, bw, bh = map(float, parts[1:5])\n",
        "                x_min, y_min, x_max, y_max = yolo_to_pascal((cx, cy, bw, bh), w0, h0)\n",
        "                # scale to half-size\n",
        "                scale_x = half / float(w0)\n",
        "                scale_y = half / float(h0)\n",
        "                xmin2 = x_min * scale_x + x_off\n",
        "                ymin2 = y_min * scale_y + y_off\n",
        "                xmax2 = x_max * scale_x + x_off\n",
        "                ymax2 = y_max * scale_y + y_off\n",
        "                if xmax2 - xmin2 < 3 or ymax2 - ymin2 < 3:\n",
        "                    continue\n",
        "                accumulated_boxes.append([xmin2, ymin2, xmax2, ymax2])\n",
        "                accumulated_labels.append(lab)\n",
        "\n",
        "    if not accumulated_boxes:\n",
        "        return False\n",
        "\n",
        "    # Save mosaic image and write labels\n",
        "    cv2.imwrite(str(out_image_path), canvas)\n",
        "    ih, iw = canvas.shape[:2]\n",
        "    with open(out_label_path, \"w\") as olf:\n",
        "        for lab, box in zip(accumulated_labels, accumulated_boxes):\n",
        "            yolo_box = pascal_to_yolo(box, iw, ih)\n",
        "            cx, cy, bw, bh = [max(0.0, min(1.0, v)) for v in yolo_box]\n",
        "            olf.write(f\"{lab} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
        "    return True\n",
        "\n",
        "\n",
        "candidates = [p.stem for p in (labels_dir).glob(\"*.txt\")]\n",
        "NUM_MOSAICS = 200\n",
        "mosaics_created = 0\n",
        "\n",
        "if len(candidates) >= 4:\n",
        "    for i in range(NUM_MOSAICS):\n",
        "        picks = random.sample(candidates, 4)\n",
        "        new_base = f\"mosaic_{uuid.uuid4().hex[:8]}\"\n",
        "        out_img = images_dir / (new_base + \".jpg\")\n",
        "        out_lbl = labels_dir / (new_base + \".txt\")\n",
        "        ok = create_mosaic_image(picks, images_dir, labels_dir, out_img, out_lbl, target_size=640)\n",
        "        if ok:\n",
        "            mosaics_created += 1\n",
        "\n",
        "print(f\"Created {mosaics_created} mosaic images.\")\n"
      ],
      "metadata": {
        "id": "3FcCeZW22dHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_counts_after = count_bboxes_in_labels(os.path.join(train_dir, \"labels\"))\n",
        "\n",
        "print(\"\\nPer-class counts BEFORE augmentation (train):\")\n",
        "for i, name in enumerate(classes):\n",
        "    print(f\"{i:02d} {name:15s}: {train_counts.get(i,0)}\")\n",
        "\n",
        "print(\"\\nPer-class counts AFTER augmentation (train):\")\n",
        "for i, name in enumerate(classes):\n",
        "    print(f\"{i:02d} {name:15s}: {train_counts_after.get(i,0)}\")\n",
        "\n",
        "total_before = sum(train_counts.values())\n",
        "total_after = sum(train_counts_after.values())\n",
        "print(f\"\\nTotal annotated boxes: before={total_before}, after={total_after}, added={total_after - total_before}\")\n"
      ],
      "metadata": {
        "id": "yW_B5vlJ33nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load pretrained YOLO model\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# You can train the model with customized settings\n",
        "results = model.train(\n",
        "    data=\"/content/open_images_data/data.yaml\",\n",
        "    epochs=30,\n",
        "    imgsz=640,                     # Set image size\n",
        "    batch=16,\n",
        "    project=\"/content/drive/MyDrive/YOLOv11_training results\",  # Save to Google Drive\n",
        "    name=\"yolo_experiment\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "W5MKIIQvx8Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "# Define paths\n",
        "model_path = '/content/drive/MyDrive/YOLOv11_training results/yolo_experiment/weights/best.pt'\n",
        "input_folder = '/content/drive/MyDrive/fruits and vegies'    # Folder containing test images\n",
        "output_folder = '/content/drive/MyDrive/vegetables(open_images) detection'       # Folder to save detection results\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Make sure output folder exists\n",
        "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Process each image in the input folder\n",
        "for img_file in os.listdir(input_folder):\n",
        "    img_path = os.path.join(input_folder, img_file)\n",
        "\n",
        "    # Run inference\n",
        "    results = model(img_path)\n",
        "\n",
        "    # Save each result individually\n",
        "    for i, result in enumerate(results):\n",
        "        # Get the output path\n",
        "        output_path = os.path.join(output_folder, f\"annotated_{img_file}\")\n",
        "\n",
        "        # Save each annotated image to the output folder\n",
        "        result.save(output_path)\n",
        "\n",
        "    print(f\"Processed {img_file}, results saved to {output_folder}\")\n"
      ],
      "metadata": {
        "id": "OLY-PBOO2t7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1L1-7s7O_4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}